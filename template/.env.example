# Python Backend Configuration
TETHER_HOST=127.0.0.1
TETHER_PORT=8000

# LLM Backend: local, openai, or mock
TETHER_LLM_BACKEND=local

# For local LLM (llama-cpp-python)
TETHER_MODEL_PATH=./models/your-model.gguf
TETHER_CONTEXT_LENGTH=4096

# For OpenAI API
OPENAI_API_KEY=sk-your-api-key
TETHER_OPENAI_MODEL=gpt-4o-mini

# Model parameters
TETHER_DEFAULT_TEMPERATURE=0.7
TETHER_DEFAULT_MAX_TOKENS=1024
