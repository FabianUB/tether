# Python Backend Configuration
TETHER_HOST=127.0.0.1
TETHER_PORT=8000

# LLM Backend: local, ollama, openai, gemini, or mock
TETHER_LLM_BACKEND=local

# For local LLM (llama-cpp-python)
TETHER_MODEL_PATH=./models/your-model.gguf
TETHER_CONTEXT_LENGTH=4096

# For OpenAI API
OPENAI_API_KEY=sk-your-api-key
TETHER_OPENAI_MODEL=gpt-4o-mini

# For Google Gemini API
GEMINI_API_KEY=your-gemini-api-key
TETHER_GEMINI_MODEL=gemini-2.0-flash

# Model parameters
TETHER_DEFAULT_TEMPERATURE=0.7
TETHER_DEFAULT_MAX_TOKENS=1024
